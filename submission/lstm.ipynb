{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import yfinance as yf\n",
    "start_date = datetime.datetime(2018, 1, 1)\n",
    "end_date = datetime.datetime(2024, 1, 1)\n",
    "btc_info = yf.Ticker(\"BTC-USD\")\n",
    "\n",
    "# pass the parameters as the taken dates for start and end\n",
    "df_day = btc_info.history(start = start_date, end = end_date) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fng_index = pd.read_csv(\"fng_index.csv\")\n",
    "fng_index[\"date\"] = pd.to_datetime(fng_index.date, format = \"%d-%m-%Y\")\n",
    "fng_index.set_index(\"date\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = df_day.tz_localize(None)\n",
    "df_day = pd.concat([df_day, fng_index], axis=1)\n",
    "df_day.drop(columns = [\"Dividends\", \"Stock Splits\", \"fng_classification\"], inplace = True)\n",
    "df_day.columns = ['open', 'high', 'low', 'close', 'Volume_BTC', 'fng_value']\n",
    "df_day[\"Volume_BTC\"] = df_day[\"Volume_BTC\"]/df_day[\"close\"]\n",
    "df_day[\"Volume_BTC\"] = np.log(df_day[\"Volume_BTC\"] + 1)\n",
    "df_day['RSI']=ta.rsi(df_day.close, length=15)\n",
    "df_day['EMA'] = ta.ema(df_day.close, length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_diff = df_day.diff()\n",
    "df_day_diff[\"Volume_BTC\"] = df_day[\"Volume_BTC\"].copy()\n",
    "df_day_diff[\"RSI\"] = df_day[\"RSI\"].copy()\n",
    "df_day_diff[\"EMA\"] = df_day[\"EMA\"].copy()\n",
    "df_day_diff[\"fng_value\"] = df_day[\"fng_value\"].copy()\n",
    "df_day_diff[[\"open\", \"high\", \"low\", \"close\"]] = df_day_diff[[\"open\", \"high\", \"low\", \"close\"]]/df_day[[\"open\", \"high\", \"low\", \"close\"]].shift()\n",
    "df_day_diff[\"EMA_return\"] = ta.ema(df_day_diff.close, length = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split (Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def split(self, df, start, test_start, end):\n",
    "        \"\"\"Split df into df_train and df_test by training and testing period\"\"\"\n",
    "\n",
    "        date_index = pd.to_datetime(df.index)\n",
    "        mask_train = pd.Series(date_index).between(start, test_start, inclusive=\"left\")\n",
    "        df_train = df.loc[mask_train.values].copy(deep=True)\n",
    "\n",
    "        mask_test = pd.Series(date_index).between(test_start, end, inclusive=\"left\")\n",
    "        df_test = df.loc[mask_test.values].copy(deep=True)\n",
    "\n",
    "        return df_train, df_test\n",
    "    \n",
    "    def transform(self, df_train, df_test, method = \"minmax\", y_name = \"close\"):\n",
    "        \"\"\"Perform transformation on df_train and df_test\"\"\"\n",
    "        df_train = df_train.copy(deep=True)\n",
    "        df_test = df_test.copy(deep=True)\n",
    "        X_names = list(df_train.columns[df_train.columns != y_name])\n",
    "\n",
    "        if method == \"std\":\n",
    "            self.scaler_y = StandardScaler()\n",
    "            self.scaler = StandardScaler()\n",
    "        elif method == \"minmax\":\n",
    "            self.scaler_y = MinMaxScaler()\n",
    "            self.scaler = MinMaxScaler()\n",
    "        \n",
    "        # Fit using df_train\n",
    "        self.scaler_y.fit(df_train[[y_name]])\n",
    "        self.scaler.fit(df_train[X_names])\n",
    "\n",
    "        # Transform df_train and df_test\n",
    "        df_train.loc[:, [y_name]] = self.scaler_y.transform(df_train[[y_name]])\n",
    "        df_train.loc[:, X_names] = self.scaler.transform(df_train[X_names])\n",
    "        df_test.loc[:, [y_name]] = self.scaler_y.transform(df_test[[y_name]])\n",
    "        df_test.loc[:, X_names] = self.scaler.transform(df_test[X_names])\n",
    "\n",
    "        return df_train, df_test\n",
    "    \n",
    "    def generate_dataset(self, df, seq_len, y_name = \"close\"):\n",
    "        \"\"\"Use df to generate arrays X and y for keras\"\"\"\n",
    "        X_list, y_list = [], []\n",
    "        for i in range(len(df.index) - seq_len):\n",
    "            if df.iloc[i:i + 1 + seq_len,:].isna().any(axis = None):\n",
    "                continue\n",
    "            X_list.append(np.array(df.iloc[i:i+seq_len,:]))\n",
    "            y_list.append(df[y_name].values[i+seq_len])\n",
    "        return np.array(X_list), np.array(y_list)\n",
    "    \n",
    "    def pipeline(self, \n",
    "                 split_args = {\"start\": \"2021-10-01\", \n",
    "                               \"test_start\": \"2021-12-31\", \n",
    "                               \"end\" :\"2022-01-01\"}, \n",
    "                 transform_args = {\"method\": \"minmax\", \n",
    "                                   \"y_name\": \"close\"}, LAG = 5):\n",
    "        self.df_train, self.df_test = self.split(self.df, **split_args)\n",
    "        self.df_train_transformed, self.df_test_transformed = self.transform(self.df_train, self.df_test, **transform_args)\n",
    "        \n",
    "        # Add LAG number of observations in training dataset to test dataset\n",
    "        df_test_LAG = pd.concat((self.df_train_transformed.iloc[-LAG:,:], self.df_test_transformed), axis=0)\n",
    "\n",
    "        self.X_train, self.y_train = self.generate_dataset(self.df_train_transformed, seq_len=LAG)\n",
    "        self.X_test, self.y_test = self.generate_dataset(df_test_LAG, seq_len=LAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>fng_value</th>\n",
       "      <th>RSI</th>\n",
       "      <th>EMA</th>\n",
       "      <th>EMA_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.532534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>0.097011</td>\n",
       "      <td>13.932804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>0.014611</td>\n",
       "      <td>13.919800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>0.026196</td>\n",
       "      <td>14.149431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>0.117333</td>\n",
       "      <td>14.128750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>51.750421</td>\n",
       "      <td>41886.577281</td>\n",
       "      <td>-0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>51.750421</td>\n",
       "      <td>41886.577281</td>\n",
       "      <td>-0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.750421</td>\n",
       "      <td>41886.577281</td>\n",
       "      <td>-0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>51.750421</td>\n",
       "      <td>41886.577281</td>\n",
       "      <td>-0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>51.750421</td>\n",
       "      <td>41886.577281</td>\n",
       "      <td>-0.001882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2292 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               close  Volume_BTC  fng_value        RSI           EMA  \\\n",
       "2018-01-01       NaN   13.532534        NaN        NaN           NaN   \n",
       "2018-01-02  0.097011   13.932804        NaN        NaN           NaN   \n",
       "2018-01-03  0.014611   13.919800        NaN        NaN           NaN   \n",
       "2018-01-04  0.026196   14.149431        NaN        NaN           NaN   \n",
       "2018-01-05  0.117333   14.128750        NaN        NaN           NaN   \n",
       "...              ...         ...        ...        ...           ...   \n",
       "2024-04-06       NaN         NaN       75.0  51.750421  41886.577281   \n",
       "2024-04-07       NaN         NaN       78.0  51.750421  41886.577281   \n",
       "2024-04-08       NaN         NaN       76.0  51.750421  41886.577281   \n",
       "2024-04-09       NaN         NaN       80.0  51.750421  41886.577281   \n",
       "2024-04-10       NaN         NaN       78.0  51.750421  41886.577281   \n",
       "\n",
       "            EMA_return  \n",
       "2018-01-01         NaN  \n",
       "2018-01-02         NaN  \n",
       "2018-01-03         NaN  \n",
       "2018-01-04         NaN  \n",
       "2018-01-05         NaN  \n",
       "...                ...  \n",
       "2024-04-06   -0.001882  \n",
       "2024-04-07   -0.001882  \n",
       "2024-04-08   -0.001882  \n",
       "2024-04-09   -0.001882  \n",
       "2024-04-10   -0.001882  \n",
       "\n",
       "[2292 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day_diff[[\"close\", \"Volume_BTC\", \"fng_value\", \"RSI\", \"EMA\", \"EMA_return\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate datasets\n",
    "split_args = {\"start\": \"2018-01-01\", \n",
    "              \"test_start\": \"2023-01-01\", \n",
    "              \"end\" :\"2024-01-01\"}\n",
    "transform_args = {\"method\": \"std\", \n",
    "                  \"y_name\": \"close\"}\n",
    "df_input = df_day_diff[[\"close\", \"Volume_BTC\", \"fng_value\", \"RSI\", \"EMA\", \"EMA_return\"]]\n",
    "\n",
    "pp_day_5 = preprocessing(df_input)\n",
    "pp_day_5.pipeline(LAG = 5, split_args = split_args, transform_args = transform_args)\n",
    "\n",
    "pp_day_30 = preprocessing(df_input)\n",
    "pp_day_30.pipeline(LAG = 30, split_args = split_args, transform_args = transform_args)\n",
    "\n",
    "pp_day_90 = preprocessing(df_input)\n",
    "pp_day_90.pipeline(LAG = 90, split_args = split_args, transform_args = transform_args)\n",
    "\n",
    "pp_day_180 = preprocessing(df_input)\n",
    "pp_day_180.pipeline(LAG = 180, split_args = split_args, transform_args = transform_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_day_5 = pp_day_5.X_train\n",
    "X_test_day_5 = pp_day_5.X_test\n",
    "y_train_day_5 = pp_day_5.y_train\n",
    "y_test_day_5 = pp_day_5.y_test\n",
    "\n",
    "X_train_day_30 = pp_day_30.X_train\n",
    "X_test_day_30 = pp_day_30.X_test\n",
    "y_train_day_30 = pp_day_30.y_train\n",
    "y_test_day_30 = pp_day_30.y_test\n",
    "\n",
    "X_train_day_90 = pp_day_90.X_train\n",
    "X_test_day_90 = pp_day_90.X_test\n",
    "y_train_day_90 = pp_day_90.y_train\n",
    "y_test_day_90 = pp_day_90.y_test\n",
    "\n",
    "X_train_day_180 = pp_day_180.X_train\n",
    "X_test_day_180 = pp_day_180.X_test\n",
    "y_train_day_180 = pp_day_180.y_train\n",
    "y_test_day_180 = pp_day_180.y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, AveragePooling1D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf.keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "    tf.keras.metrics.RootMeanSquaredError(name='rmse')\n",
    "]\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_rmse', min_delta=0, patience=5, verbose=1,\n",
    "    mode='min', baseline=None, restore_best_weights=True)]\n",
    "\n",
    "def model_builder_lstm(hp):\n",
    "    hp_lstm_depth = hp.Int('lstm_depth', min_value=1, max_value=4, step=1)\n",
    "    hp_lstm_size = hp.Choice('lstm_size', values = [8, 16, 32, 64])\n",
    "    hp_lstm_dropout = hp.Choice('lstm_dropout', values = [0.2, 0.5, 0.8])\n",
    "\n",
    "    hp_dense_depth = hp.Int('dense_depth', min_value=1, max_value=4, step=1)\n",
    "    hp_dense_size = hp.Choice('dense_size', values = [8, 16, 32, 64])\n",
    "    hp_dense_dropout = hp.Choice('dense_dropout', values = [0.2, 0.5, 0.8])\n",
    "\n",
    "    hp_lr = 0.001\n",
    "    \n",
    "    model = Sequential()\n",
    "    for i in range(hp_lstm_depth-1):\n",
    "        model.add(LSTM(hp_lstm_size, return_sequences=True, dropout = hp_lstm_dropout))\n",
    "    model.add(LSTM(hp_lstm_size, return_sequences=False, dropout = hp_lstm_dropout))\n",
    "    \n",
    "    for i in range(hp_dense_depth):\n",
    "        model.add(Dense(hp_dense_size, activation = \"relu\"))\n",
    "        model.add(Dropout(hp_dense_dropout))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp_lr),\n",
    "        loss='mse',\n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_conv_lstm(hp):\n",
    "    hp_conv_filters = hp.Choice('conv_filters', values = [8, 16, 32, 64, 128])\n",
    "    hp_conv_kernel_size = hp.Int('kernel_size', min_value=3, max_value=9, step=2)\n",
    "    \n",
    "    hp_lstm_depth = hp.Int('lstm_depth', min_value=2, max_value=4, step=1)\n",
    "    hp_lstm_size = hp.Choice('lstm_size', values = [8, 16, 32, 64])\n",
    "    hp_lstm_dropout = hp.Choice('lstm_dropout', values = [0.2, 0.5, 0.8])\n",
    "\n",
    "    hp_dense_depth = hp.Int('dense_depth', min_value=1, max_value=4, step=1)\n",
    "    hp_dense_size = hp.Choice('dense_size', values = [8, 16, 32, 64])\n",
    "    hp_dense_dropout = hp.Choice('dense_dropout', values = [0.2, 0.5, 0.8])\n",
    "\n",
    "    hp_lr = 0.001\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(hp_conv_filters, hp_conv_kernel_size, padding = \"same\"))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    for i in range(hp_lstm_depth-1):\n",
    "        model.add(LSTM(hp_lstm_size, return_sequences=True, dropout = hp_lstm_dropout))\n",
    "    model.add(LSTM(hp_lstm_size, return_sequences=False, dropout = hp_lstm_dropout))\n",
    "    \n",
    "    for i in range(hp_dense_depth):\n",
    "        model.add(Dense(hp_dense_size, activation = \"relu\"))\n",
    "        model.add(Dropout(hp_dense_dropout))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp_lr),\n",
    "        loss='mse',\n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_conv_lstm2(hp):\n",
    "    hp_conv_depth = hp.Int('conv_size', min_value=1, max_value=3, step=1)\n",
    "    hp_conv_filters = hp.Choice('conv_filters', values = [8, 16, 32, 64, 128])\n",
    "    hp_conv_kernel_size = hp.Int('kernel_size', min_value = 3, max_value = 33, step = 5)\n",
    "    \n",
    "    hp_lstm_depth = hp.Int('lstm_depth', min_value=2, max_value=4, step=1)\n",
    "    hp_lstm_size = hp.Choice('lstm_size', values = [8, 16, 32, 64])\n",
    "    hp_lstm_dropout = hp.Choice('lstm_dropout', values = [0.2, 0.5, 0.8])\n",
    "\n",
    "    hp_dense_depth = hp.Int('dense_depth', min_value=1, max_value=4, step=1)\n",
    "    hp_dense_size = hp.Choice('dense_size', values = [8, 16, 32, 64])\n",
    "    hp_dense_dropout = hp.Choice('dense_dropout', values = [0.2, 0.5, 0.8])\n",
    "\n",
    "    hp_lr = 0.001\n",
    "    \n",
    "    model = Sequential()\n",
    "    for i in range(hp_conv_depth):\n",
    "        model.add(Conv1D(hp_conv_filters, hp_conv_kernel_size, padding = \"same\", activation = \"relu\"))\n",
    "        model.add(AveragePooling1D(pool_size=2))\n",
    "\n",
    "    for i in range(hp_lstm_depth-1):\n",
    "        model.add(LSTM(hp_lstm_size, return_sequences=True, dropout = hp_lstm_dropout))\n",
    "    model.add(LSTM(hp_lstm_size, return_sequences=False, dropout = hp_lstm_dropout))\n",
    "    \n",
    "    for i in range(hp_dense_depth):\n",
    "        model.add(Dense(hp_dense_size, activation = \"relu\"))\n",
    "        model.add(Dropout(hp_dense_dropout))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp_lr),\n",
    "        loss='mse',\n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_conv_lstm3(hp):\n",
    "    hp_conv_depth = hp.Int('conv_size', min_value=1, max_value=4, step=1)\n",
    "    hp_conv_filters = hp.Choice('conv_filters', values = [8, 16, 32, 64, 128])\n",
    "    hp_conv_kernel_size = hp.Int('kernel_size', min_value = 3, max_value = 31, step = 4)\n",
    "    \n",
    "    hp_lstm_depth = hp.Int('lstm_depth', min_value=2, max_value=4, step=1)\n",
    "    hp_lstm_size = hp.Choice('lstm_size', values = [8, 16, 32, 64])\n",
    "    hp_lstm_dropout = hp.Choice('lstm_dropout', values = [0.2, 0.5, 0.8])\n",
    "\n",
    "    hp_dense_depth = hp.Int('dense_depth', min_value=1, max_value=4, step=1)\n",
    "    hp_dense_size = hp.Choice('dense_size', values = [8, 16, 32, 64])\n",
    "    hp_dense_dropout = hp.Choice('dense_dropout', values = [0.2, 0.5, 0.8])\n",
    "\n",
    "    hp_lr = 0.001\n",
    "    \n",
    "    model = Sequential()\n",
    "    for i in range(hp_conv_depth):\n",
    "        model.add(Conv1D(hp_conv_filters, hp_conv_kernel_size, padding = \"same\", activation = \"relu\"))\n",
    "        model.add(AveragePooling1D(pool_size=2))\n",
    "\n",
    "    for i in range(hp_lstm_depth-1):\n",
    "        model.add(LSTM(hp_lstm_size, return_sequences=True, dropout = hp_lstm_dropout))\n",
    "    model.add(LSTM(hp_lstm_size, return_sequences=False, dropout = hp_lstm_dropout))\n",
    "    \n",
    "    for i in range(hp_dense_depth):\n",
    "        model.add(Dense(hp_dense_size, activation = \"relu\"))\n",
    "        model.add(Dropout(hp_dense_dropout))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp_lr),\n",
    "        loss='mse',\n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close = df_day[(df_day.index >= \"2023-01-01\")*(df_day.index < \"2024-01-01\")].close.copy()\n",
    "naive_pred = df_day[(df_day.index >= \"2022-12-31\")*(df_day.index < \"2023-12-31\")].close.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_day_5 = kt.RandomSearch(\n",
    "    model_builder_lstm,\n",
    "    objective = 'val_loss',\n",
    "    max_trials = 50,  # Number of different configurations to try\n",
    "    executions_per_trial = 1,  # Number of models to train for each trial\n",
    "    seed = 4012,\n",
    "    overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 07s]\n",
      "val_loss: 0.3728318214416504\n",
      "\n",
      "Best val_loss So Far: 0.3553650975227356\n",
      "Total elapsed time: 00h 06m 22s\n"
     ]
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_rmse', min_delta=0, patience=10, verbose=1,\n",
    "    mode='min', baseline=None, restore_best_weights=True)]\n",
    "tuner_day_5.search(\n",
    "    X_train_day_5[:(len(X_train_day_5)-100)], y_train_day_5[:(len(y_train_day_5)-100)],\n",
    "    epochs=50,\n",
    "    validation_data = (X_train_day_5[-100:], y_train_day_5[-100:]),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9533 - mae: 0.5744 - rmse: 0.8621 \n",
      "Epoch 2/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9562 - mae: 0.6616 - rmse: 0.9770 \n",
      "Epoch 3/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9495 - mae: 0.6594 - rmse: 0.9737 \n",
      "Epoch 4/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9462 - mae: 0.6583 - rmse: 0.9720 \n",
      "Epoch 5/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9429 - mae: 0.6568 - rmse: 0.9703 \n",
      "Epoch 6/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9467 - mae: 0.6597 - rmse: 0.9722 \n",
      "Epoch 7/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9442 - mae: 0.6570 - rmse: 0.9709 \n",
      "Epoch 8/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9506 - mae: 0.6588 - rmse: 0.9742 \n",
      "Epoch 9/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9512 - mae: 0.6611 - rmse: 0.9745 \n",
      "Epoch 10/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9463 - mae: 0.6574 - rmse: 0.9720 \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "naive: 430132.6457969352\n",
      "model_day_5: 429587.36711979203\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(4012)\n",
    "best_hps_day_5 = tuner_day_5.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_day_5 = tuner_day_5.hypermodel.build(best_hps_day_5)\n",
    "model_day_5.fit(X_train_day_5, y_train_day_5,\n",
    "                batch_size=64, epochs=10)\n",
    "pred_return_day_5 = pp_day_5.scaler_y.inverse_transform(model_day_5.predict(X_test_day_5))[:,0]\n",
    "pred_close_day_5 = naive_pred*(pred_return_day_5+1)\n",
    "print(f\"naive: {np.mean((test_close - naive_pred)**2)}\")\n",
    "print(f\"model_day_5: {np.mean((test_close - pred_close_day_5)**2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstm_depth': 1,\n",
       " 'lstm_size': 8,\n",
       " 'lstm_dropout': 0.2,\n",
       " 'dense_depth': 4,\n",
       " 'dense_size': 32,\n",
       " 'dense_dropout': 0.2}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps_day_5.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,909</span> (46.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,909\u001b[0m (46.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,969</span> (15.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,969\u001b[0m (15.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,940</span> (31.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m7,940\u001b[0m (31.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_day_5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_day_30 = kt.RandomSearch(\n",
    "    model_builder_lstm,\n",
    "    objective = 'val_loss',\n",
    "    max_trials = 50,  # Number of different configurations to try\n",
    "    executions_per_trial = 1,  # Number of models to train for each trial\n",
    "    seed = 4012,\n",
    "    overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 12s]\n",
      "val_loss: 0.37423720955848694\n",
      "\n",
      "Best val_loss So Far: 0.36132171750068665\n",
      "Total elapsed time: 00h 10m 03s\n"
     ]
    }
   ],
   "source": [
    "tuner_day_30.search(\n",
    "    X_train_day_30[:(len(X_train_day_30)-100)], y_train_day_30[:(len(y_train_day_30)-100)],\n",
    "    epochs=50,\n",
    "    validation_data = (X_train_day_30[-100:], y_train_day_30[-100:]),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.9261 - mae: 0.5853 - rmse: 0.8635 - val_loss: 0.3585 - val_mae: 0.4000 - val_rmse: 0.6001\n",
      "Epoch 2/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8759 - mae: 0.6389 - rmse: 0.9350 - val_loss: 0.3592 - val_mae: 0.4007 - val_rmse: 0.6004\n",
      "Epoch 3/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8795 - mae: 0.6364 - rmse: 0.9369 - val_loss: 0.3589 - val_mae: 0.4012 - val_rmse: 0.6001\n",
      "Epoch 4/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8760 - mae: 0.6382 - rmse: 0.9354 - val_loss: 0.3584 - val_mae: 0.4012 - val_rmse: 0.5999\n",
      "Epoch 5/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8758 - mae: 0.6370 - rmse: 0.9350 - val_loss: 0.3594 - val_mae: 0.3998 - val_rmse: 0.6004\n",
      "Epoch 6/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8698 - mae: 0.6355 - rmse: 0.9319 - val_loss: 0.3610 - val_mae: 0.4002 - val_rmse: 0.6016\n",
      "Epoch 7/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8839 - mae: 0.6406 - rmse: 0.9396 - val_loss: 0.3603 - val_mae: 0.3999 - val_rmse: 0.6011\n",
      "Epoch 8/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8778 - mae: 0.6405 - rmse: 0.9362 - val_loss: 0.3579 - val_mae: 0.3989 - val_rmse: 0.5993\n",
      "Epoch 9/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8741 - mae: 0.6397 - rmse: 0.9342 - val_loss: 0.3567 - val_mae: 0.3991 - val_rmse: 0.5984\n",
      "Epoch 10/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8739 - mae: 0.6373 - rmse: 0.9340 - val_loss: 0.3561 - val_mae: 0.3990 - val_rmse: 0.5978\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "naive: 430132.6457969352\n",
      "model_day_30: 428745.55999080214\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(4019)\n",
    "best_hps_day_30 = tuner_day_30.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_day_30 = tuner_day_30.hypermodel.build(best_hps_day_30)\n",
    "model_day_30.fit(X_train_day_30, y_train_day_30,\n",
    "                batch_size=64, epochs=10, validation_data = (X_test_day_30, y_test_day_30))\n",
    "pred_return_day_30 = pp_day_30.scaler_y.inverse_transform(model_day_30.predict(X_test_day_30))[:,0]\n",
    "pred_close_day_30 = naive_pred*(pred_return_day_30+1)\n",
    "print(f\"naive: {np.mean((test_close - naive_pred)**2)}\")\n",
    "print(f\"model_day_30: {np.mean((test_close - pred_close_day_30)**2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstm_depth': 1,\n",
       " 'lstm_size': 32,\n",
       " 'lstm_dropout': 0.2,\n",
       " 'dense_depth': 1,\n",
       " 'dense_size': 8,\n",
       " 'dense_dropout': 0.5}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps_day_30.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv1D-Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_day_30_CL = kt.RandomSearch(\n",
    "    model_builder_conv_lstm,\n",
    "    objective='val_loss',\n",
    "    max_trials=30,  # Number of different configurations to try\n",
    "    executions_per_trial=1,  # Number of models to train for each trial\n",
    "    seed = 4012,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 10s]\n",
      "val_loss: 0.5308324694633484\n",
      "\n",
      "Best val_loss So Far: 0.5267766714096069\n",
      "Total elapsed time: 00h 04m 35s\n"
     ]
    }
   ],
   "source": [
    "tuner_day_30_CL.search(\n",
    "    X_train_day_30, y_train_day_30,\n",
    "    epochs=10,\n",
    "    validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.8717 - mae: 0.6491 - rmse: 0.9617\n",
      "Epoch 2/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8779 - mae: 0.6396 - rmse: 0.9362\n",
      "Epoch 3/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8730 - mae: 0.6395 - rmse: 0.9335\n",
      "Epoch 4/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8761 - mae: 0.6408 - rmse: 0.9352\n",
      "Epoch 5/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8787 - mae: 0.6430 - rmse: 0.9366\n",
      "Epoch 6/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8767 - mae: 0.6400 - rmse: 0.9354\n",
      "Epoch 7/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8755 - mae: 0.6378 - rmse: 0.9348\n",
      "Epoch 8/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8748 - mae: 0.6393 - rmse: 0.9346\n",
      "Epoch 9/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8794 - mae: 0.6413 - rmse: 0.9370\n",
      "Epoch 10/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8833 - mae: 0.6406 - rmse: 0.9390\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
      "naive: 430132.6457969352\n",
      "model_day_30_CL: 428483.11722955777\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(4019)\n",
    "best_hps_day_30_CL = tuner_day_30_CL.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_day_30_CL = tuner_day_30_CL.hypermodel.build(best_hps_day_30_CL)\n",
    "model_day_30_CL.fit(X_train_day_30, y_train_day_30,\n",
    "                batch_size=64, epochs=10)\n",
    "pred_return_day_30_CL = pp_day_30.scaler_y.inverse_transform(model_day_30_CL.predict(X_test_day_30))[:,0]\n",
    "pred_close_day_30_CL = naive_pred*(pred_return_day_30_CL+1)\n",
    "print(f\"naive: {np.mean((test_close - naive_pred)**2)}\")\n",
    "print(f\"model_day_30_CL: {np.mean((test_close - pred_close_day_30_CL)**2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_filters': 128,\n",
       " 'kernel_size': 7,\n",
       " 'lstm_depth': 4,\n",
       " 'lstm_size': 32,\n",
       " 'lstm_dropout': 0.5,\n",
       " 'dense_depth': 2,\n",
       " 'dense_size': 32,\n",
       " 'dense_dropout': 0.2}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps_day_30_CL.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_day_90= kt.RandomSearch(\n",
    "    model_builder_lstm,\n",
    "    objective = 'val_loss',\n",
    "    max_trials = 50,  # Number of different configurations to try\n",
    "    executions_per_trial = 1,  # Number of models to train for each trial\n",
    "    seed = 4012,\n",
    "    overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 13s]\n",
      "val_loss: 0.3785862922668457\n",
      "\n",
      "Best val_loss So Far: 0.3671008348464966\n",
      "Total elapsed time: 00h 15m 00s\n"
     ]
    }
   ],
   "source": [
    "tuner_day_90.search(\n",
    "    X_train_day_90[:(len(X_train_day_90)-100)], y_train_day_90[:(len(y_train_day_90)-100)],\n",
    "    epochs=10,\n",
    "    validation_data = (X_train_day_90[-100:], y_train_day_90[-100:]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.8943 - mae: 0.5649 - rmse: 0.8408 - val_loss: 0.3570 - val_mae: 0.4054 - val_rmse: 0.5991\n",
      "Epoch 2/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9159 - mae: 0.6595 - rmse: 0.9570 - val_loss: 0.3560 - val_mae: 0.4030 - val_rmse: 0.5980\n",
      "Epoch 3/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9099 - mae: 0.6498 - rmse: 0.9539 - val_loss: 0.3542 - val_mae: 0.4049 - val_rmse: 0.5965\n",
      "Epoch 4/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9005 - mae: 0.6408 - rmse: 0.9489 - val_loss: 0.3538 - val_mae: 0.4047 - val_rmse: 0.5962\n",
      "Epoch 5/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8970 - mae: 0.6434 - rmse: 0.9470 - val_loss: 0.3538 - val_mae: 0.4023 - val_rmse: 0.5962\n",
      "Epoch 6/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8792 - mae: 0.6404 - rmse: 0.9375 - val_loss: 0.3545 - val_mae: 0.4014 - val_rmse: 0.5968\n",
      "Epoch 7/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8788 - mae: 0.6428 - rmse: 0.9372 - val_loss: 0.3550 - val_mae: 0.4014 - val_rmse: 0.5972\n",
      "Epoch 8/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8887 - mae: 0.6402 - rmse: 0.9426 - val_loss: 0.3545 - val_mae: 0.4018 - val_rmse: 0.5968\n",
      "Epoch 9/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8796 - mae: 0.6414 - rmse: 0.9377 - val_loss: 0.3541 - val_mae: 0.4012 - val_rmse: 0.5965\n",
      "Epoch 10/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8817 - mae: 0.6388 - rmse: 0.9389 - val_loss: 0.3548 - val_mae: 0.4022 - val_rmse: 0.5971\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "naive: 430132.6457969352\n",
      "model_day_90: 427139.73300267436\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(4012)\n",
    "best_hps_day_90 = tuner_day_90.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_day_90 = tuner_day_90.hypermodel.build(best_hps_day_90)\n",
    "model_day_90.fit(X_train_day_90, y_train_day_90,\n",
    "                batch_size=64, epochs=10, validation_data = (X_test_day_90, y_test_day_90))\n",
    "pred_return_day_90 = pp_day_90.scaler_y.inverse_transform(model_day_90.predict(X_test_day_90))[:,0]\n",
    "pred_close_day_90 = naive_pred*(pred_return_day_90+1)\n",
    "print(f\"naive: {np.mean((test_close - naive_pred)**2)}\")\n",
    "print(f\"model_day_90: {np.mean((test_close - pred_close_day_90)**2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv1D-Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_day_90_CL = kt.RandomSearch(\n",
    "    model_builder_conv_lstm2,\n",
    "    objective='val_loss',\n",
    "    max_trials=30,  # Number of different configurations to try\n",
    "    executions_per_trial=1,  # Number of models to train for each trial\n",
    "    seed = 4012,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 12s]\n",
      "val_loss: 0.4723556935787201\n",
      "\n",
      "Best val_loss So Far: 0.4709326922893524\n",
      "Total elapsed time: 00h 06m 04s\n"
     ]
    }
   ],
   "source": [
    "tuner_day_90_CL.search(\n",
    "    X_train_day_90, y_train_day_90,\n",
    "    epochs=10,\n",
    "    validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 1.0170 - mae: 0.3883 - rmse: 0.6366\n",
      "Epoch 2/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1.0048 - mae: 0.6600 - rmse: 1.0019\n",
      "Epoch 3/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1.0061 - mae: 0.6629 - rmse: 1.0026\n",
      "Epoch 4/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1.0073 - mae: 0.6592 - rmse: 1.0032\n",
      "Epoch 5/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.0119 - mae: 0.6613 - rmse: 1.0054\n",
      "Epoch 6/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.0108 - mae: 0.6610 - rmse: 1.0049\n",
      "Epoch 7/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.0065 - mae: 0.6586 - rmse: 1.0027\n",
      "Epoch 8/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.0092 - mae: 0.6591 - rmse: 1.0041\n",
      "Epoch 9/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.0125 - mae: 0.6608 - rmse: 1.0057\n",
      "Epoch 10/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.0076 - mae: 0.6586 - rmse: 1.0033\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
      "naive: 430132.6457969352\n",
      "model_day_90_CL: 425490.35664777627\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(4019)\n",
    "best_hps_day_90_CL = tuner_day_90_CL.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_day_90_CL = tuner_day_90_CL.hypermodel.build(best_hps_day_90_CL)\n",
    "model_day_90_CL.fit(X_train_day_90, y_train_day_90,\n",
    "                batch_size=64, epochs=10)\n",
    "pred_return_day_90_CL = pp_day_90.scaler_y.inverse_transform(model_day_90_CL.predict(X_test_day_90))[:,0]\n",
    "pred_close_day_90_CL = naive_pred*(pred_return_day_90_CL+1)\n",
    "print(f\"naive: {np.mean((test_close - naive_pred)**2)}\")\n",
    "print(f\"model_day_90_CL: {np.mean((test_close - pred_close_day_90_CL)**2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_size': 3,\n",
       " 'conv_filters': 128,\n",
       " 'kernel_size': 33,\n",
       " 'lstm_depth': 3,\n",
       " 'lstm_size': 64,\n",
       " 'lstm_dropout': 0.2,\n",
       " 'dense_depth': 1,\n",
       " 'dense_size': 32,\n",
       " 'dense_dropout': 0.2}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps_day_90_CL.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_day_180= kt.RandomSearch(\n",
    "    model_builder_lstm,\n",
    "    objective = 'val_loss',\n",
    "    max_trials = 50,  # Number of different configurations to try\n",
    "    executions_per_trial = 1,  # Number of models to train for each trial\n",
    "    seed = 4012,\n",
    "    overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 19s]\n",
      "val_loss: 0.5226165056228638\n",
      "\n",
      "Best val_loss So Far: 0.5192965269088745\n",
      "Total elapsed time: 00h 23m 25s\n"
     ]
    }
   ],
   "source": [
    "tuner_day_180.search(\n",
    "    X_train_day_180, y_train_day_180,\n",
    "    epochs=10,\n",
    "    validation_split = 0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - loss: 0.9625 - mae: 0.6570 - rmse: 0.9812\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.9494 - mae: 0.6506 - rmse: 0.9733\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.9487 - mae: 0.6531 - rmse: 0.9730\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.9308 - mae: 0.6469 - rmse: 0.9638\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.9463 - mae: 0.6530 - rmse: 0.9716\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.9484 - mae: 0.6534 - rmse: 0.9729\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - loss: 0.9455 - mae: 0.6542 - rmse: 0.9715\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.9431 - mae: 0.6508 - rmse: 0.9702\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.9435 - mae: 0.6512 - rmse: 0.9704\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.9471 - mae: 0.6519 - rmse: 0.9722\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step\n",
      "naive: 430132.6457969352\n",
      "model_day_180: 427328.6092919653\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(4012)\n",
    "best_hps_day_180 = tuner_day_180.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_day_180 = tuner_day_180.hypermodel.build(best_hps_day_180)\n",
    "model_day_180.fit(X_train_day_180, y_train_day_180,\n",
    "                batch_size=64, epochs=10)\n",
    "pred_return_day_180 = pp_day_180.scaler_y.inverse_transform(model_day_180.predict(X_test_day_180))[:,0]\n",
    "pred_close_day_180 = naive_pred*(pred_return_day_180+1)\n",
    "print(f\"naive: {np.mean((test_close - naive_pred)**2)}\")\n",
    "print(f\"model_day_180: {np.mean((test_close - pred_close_day_180)**2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder_conv_lstm3(hp):\n",
    "    hp_conv_depth = hp.Int('conv_size', min_value=1, max_value=4, step=1)\n",
    "    hp_conv_filters = hp.Choice('conv_filters', values = [8, 16, 32, 64, 128])\n",
    "    hp_conv_kernel_size = hp.Int('kernel_size', min_value = 3, max_value = 31, step = 4)\n",
    "    \n",
    "    hp_lstm_depth = hp.Int('lstm_depth', min_value=2, max_value=4, step=1)\n",
    "    hp_lstm_size = hp.Choice('lstm_size', values = [8, 16, 32, 64])\n",
    "    hp_lstm_dropout = hp.Choice('lstm_dropout', values = [0.2, 0.5, 0.8])\n",
    "\n",
    "    hp_dense_depth = hp.Int('dense_depth', min_value=1, max_value=4, step=1)\n",
    "    hp_dense_size = hp.Choice('dense_size', values = [8, 16, 32, 64])\n",
    "    hp_dense_dropout = hp.Choice('dense_dropout', values = [0.2, 0.5, 0.8])\n",
    "\n",
    "    hp_lr = 0.001\n",
    "    \n",
    "    model = Sequential()\n",
    "    for i in range(hp_conv_depth):\n",
    "        model.add(Conv1D(hp_conv_filters, hp_conv_kernel_size, padding = \"same\", activation = \"relu\"))\n",
    "        model.add(AveragePooling1D(pool_size=2))\n",
    "\n",
    "    for i in range(hp_lstm_depth-1):\n",
    "        model.add(LSTM(hp_lstm_size, return_sequences=True, dropout = hp_lstm_dropout))\n",
    "    model.add(LSTM(hp_lstm_size, return_sequences=False, dropout = hp_lstm_dropout))\n",
    "    \n",
    "    for i in range(hp_dense_depth):\n",
    "        model.add(Dense(hp_dense_size, activation = \"relu\"))\n",
    "        model.add(Dropout(hp_dense_dropout))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp_lr),\n",
    "        loss='mse',\n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_day_180_CL = kt.RandomSearch(\n",
    "    model_builder_conv_lstm3,\n",
    "    objective='val_loss',\n",
    "    max_trials=30,  # Number of different configurations to try\n",
    "    executions_per_trial=1,  # Number of models to train for each trial\n",
    "    seed = 4012,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 16s]\n",
      "val_loss: 0.5241175293922424\n",
      "\n",
      "Best val_loss So Far: 0.5194797515869141\n",
      "Total elapsed time: 00h 07m 53s\n"
     ]
    }
   ],
   "source": [
    "tuner_day_180_CL.search(\n",
    "    X_train_day_180, y_train_day_180,\n",
    "    epochs=10,\n",
    "    validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - loss: 0.9505 - mae: 0.6548 - rmse: 0.9783\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.9416 - mae: 0.6561 - rmse: 0.9694\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.9399 - mae: 0.6499 - rmse: 0.9685\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.9434 - mae: 0.6507 - rmse: 0.9702\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.9444 - mae: 0.6512 - rmse: 0.9708\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.9416 - mae: 0.6486 - rmse: 0.9693\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.9409 - mae: 0.6492 - rmse: 0.9690\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.9410 - mae: 0.6498 - rmse: 0.9691\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.9439 - mae: 0.6510 - rmse: 0.9706\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.9401 - mae: 0.6489 - rmse: 0.9686\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
      "naive: 430132.6457969352\n",
      "model_day_180_CL: 426580.15216429334\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(4012)\n",
    "best_hps_day_180_CL = tuner_day_180_CL.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_day_180_CL = tuner_day_180_CL.hypermodel.build(best_hps_day_180_CL)\n",
    "model_day_180_CL.fit(X_train_day_180, y_train_day_180,\n",
    "                batch_size=64, epochs=10)\n",
    "pred_return_day_180_CL = pp_day_180.scaler_y.inverse_transform(model_day_180_CL.predict(X_test_day_180))[:,0]\n",
    "pred_close_day_180_CL = naive_pred*(pred_return_day_180_CL+1)\n",
    "print(f\"naive: {np.mean((test_close - naive_pred)**2)}\")\n",
    "print(f\"model_day_180_CL: {np.mean((test_close - pred_close_day_180_CL)**2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling1d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">508,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling1d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">508,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling1d_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">508,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling1d_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m23,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling1d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m508,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling1d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m508,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling1d_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m508,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling1d_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,996,805</span> (19.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,996,805\u001b[0m (19.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,665,601</span> (6.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,665,601\u001b[0m (6.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,331,204</span> (12.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,331,204\u001b[0m (12.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_day_180_CL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_size': 4,\n",
       " 'conv_filters': 128,\n",
       " 'kernel_size': 31,\n",
       " 'lstm_depth': 3,\n",
       " 'lstm_size': 64,\n",
       " 'lstm_dropout': 0.2,\n",
       " 'dense_depth': 1,\n",
       " 'dense_size': 32,\n",
       " 'dense_dropout': 0.2}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps_day_180_CL.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
